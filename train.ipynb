{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_frame = 50\n",
    "\n",
    "epochs = 60\n",
    "batch_sz = 10\n",
    "checkpoint_frequency = 3\n",
    "learning_rate = 0.00005\n",
    "gamma = 0.5\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dl, val_dl, test_dl = mymodel.load_data()\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : train_dl,\n",
    "    'val' : val_dl,\n",
    "    'test' : test_dl\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "network = mymodel.get_simple_conv_net()\n",
    "network = network.to(DEVICE)\n",
    "\n",
    "optim = SGD(network.parameters(), lr=learning_rate)\n",
    "lr_sch = ExponentialLR(optim, gamma)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "stopp = mymodel.EarlyStopper(patience = 5, tolerance = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[1/60], MiniBatch[20/24], Loss: 2.57022, Acc: 9.00000, LR: 0.00005\n",
      "Eval epoch[1/60], MiniBatch[4/4], Loss: 3.14961, Acc: 6.25000                \n",
      "Train epoch[2/60], MiniBatch[20/24], Loss: 2.43751, Acc: 11.00000, LR: 0.00003\n",
      "Eval epoch[2/60], MiniBatch[4/4], Loss: 2.40664, Acc: 0.00000                 \n",
      "Train epoch[3/60], MiniBatch[20/24], Loss: 2.29651, Acc: 7.00000, LR: 0.00001\n",
      "Eval epoch[3/60], MiniBatch[4/4], Loss: 2.14750, Acc: 12.50000, Epochs without improvement: 1\n",
      "Train epoch[4/60], MiniBatch[20/24], Loss: 2.13974, Acc: 19.00000, LR: 0.00001               \n",
      "Eval epoch[4/60], MiniBatch[4/4], Loss: 2.79832, Acc: 37.50000                \n",
      "Train epoch[5/60], MiniBatch[20/24], Loss: 2.26063, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[5/60], MiniBatch[4/4], Loss: 2.04348, Acc: 37.50000                \n",
      "Train epoch[6/60], MiniBatch[20/24], Loss: 2.13804, Acc: 22.00000, LR: 0.00000\n",
      "Eval epoch[6/60], MiniBatch[4/4], Loss: 2.40010, Acc: 37.50000                \n",
      "Train epoch[7/60], MiniBatch[20/24], Loss: 2.25523, Acc: 27.00000, LR: 0.00000\n",
      "Eval epoch[7/60], MiniBatch[4/4], Loss: 2.74336, Acc: 37.50000                \n",
      "Train epoch[8/60], MiniBatch[20/24], Loss: 2.36943, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[8/60], MiniBatch[4/4], Loss: 2.18866, Acc: 43.75000                \n",
      "Train epoch[9/60], MiniBatch[20/24], Loss: 2.06075, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[9/60], MiniBatch[4/4], Loss: 2.48530, Acc: 43.75000                \n",
      "Train epoch[10/60], MiniBatch[20/24], Loss: 2.18320, Acc: 32.00000, LR: 0.00000\n",
      "Eval epoch[10/60], MiniBatch[4/4], Loss: 2.38860, Acc: 43.75000                \n",
      "Train epoch[11/60], MiniBatch[20/24], Loss: 2.33175, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[11/60], MiniBatch[4/4], Loss: 2.45214, Acc: 43.75000                \n",
      "Train epoch[12/60], MiniBatch[20/24], Loss: 2.24375, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[12/60], MiniBatch[4/4], Loss: 1.94447, Acc: 43.75000                \n",
      "Train epoch[13/60], MiniBatch[20/24], Loss: 2.26996, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[13/60], MiniBatch[4/4], Loss: 2.04026, Acc: 43.75000                \n",
      "Train epoch[14/60], MiniBatch[20/24], Loss: 2.15516, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[14/60], MiniBatch[4/4], Loss: 1.93716, Acc: 43.75000                \n",
      "Train epoch[15/60], MiniBatch[20/24], Loss: 2.21442, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[15/60], MiniBatch[4/4], Loss: 1.94812, Acc: 43.75000                \n",
      "Train epoch[16/60], MiniBatch[20/24], Loss: 2.14838, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[16/60], MiniBatch[4/4], Loss: 2.19447, Acc: 43.75000                \n",
      "Train epoch[17/60], MiniBatch[20/24], Loss: 2.25399, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[17/60], MiniBatch[4/4], Loss: 1.94466, Acc: 43.75000                \n",
      "Train epoch[18/60], MiniBatch[20/24], Loss: 2.39664, Acc: 34.00000, LR: 0.00000\n",
      "Eval epoch[18/60], MiniBatch[4/4], Loss: 2.32374, Acc: 43.75000                \n",
      "Train epoch[19/60], MiniBatch[20/24], Loss: 2.14845, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[19/60], MiniBatch[4/4], Loss: 2.40522, Acc: 43.75000                \n",
      "Train epoch[20/60], MiniBatch[20/24], Loss: 2.29933, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[20/60], MiniBatch[4/4], Loss: 2.32375, Acc: 43.75000                \n",
      "Train epoch[21/60], MiniBatch[20/24], Loss: 2.05235, Acc: 24.00000, LR: 0.00000\n",
      "Eval epoch[21/60], MiniBatch[4/4], Loss: 2.19447, Acc: 43.75000                \n",
      "Train epoch[22/60], MiniBatch[20/24], Loss: 2.33167, Acc: 27.00000, LR: 0.00000\n",
      "Eval epoch[22/60], MiniBatch[4/4], Loss: 2.19447, Acc: 43.75000                \n",
      "Train epoch[23/60], MiniBatch[20/24], Loss: 2.27284, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[23/60], MiniBatch[4/4], Loss: 2.45235, Acc: 43.75000                \n",
      "Train epoch[24/60], MiniBatch[20/24], Loss: 2.20421, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[24/60], MiniBatch[4/4], Loss: 2.32375, Acc: 43.75000                \n",
      "Train epoch[25/60], MiniBatch[20/24], Loss: 2.15835, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[25/60], MiniBatch[4/4], Loss: 1.93725, Acc: 43.75000                \n",
      "Train epoch[26/60], MiniBatch[20/24], Loss: 2.35768, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[26/60], MiniBatch[4/4], Loss: 1.94279, Acc: 43.75000                \n",
      "Train epoch[27/60], MiniBatch[20/24], Loss: 2.21910, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[27/60], MiniBatch[4/4], Loss: 2.48503, Acc: 43.75000                \n",
      "Train epoch[28/60], MiniBatch[20/24], Loss: 2.25298, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[28/60], MiniBatch[4/4], Loss: 2.74285, Acc: 43.75000                \n",
      "Train epoch[29/60], MiniBatch[20/24], Loss: 2.12193, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[29/60], MiniBatch[4/4], Loss: 1.94466, Acc: 43.75000                \n",
      "Train epoch[30/60], MiniBatch[20/24], Loss: 2.21626, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[30/60], MiniBatch[4/4], Loss: 1.94816, Acc: 43.75000                \n",
      "Train epoch[31/60], MiniBatch[20/24], Loss: 2.31501, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[31/60], MiniBatch[4/4], Loss: 2.40522, Acc: 43.75000                \n",
      "Train epoch[32/60], MiniBatch[20/24], Loss: 2.34381, Acc: 32.00000, LR: 0.00000\n",
      "Eval epoch[32/60], MiniBatch[4/4], Loss: 2.48503, Acc: 43.75000                \n",
      "Train epoch[33/60], MiniBatch[20/24], Loss: 2.19281, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[33/60], MiniBatch[4/4], Loss: 2.48503, Acc: 43.75000                \n",
      "Train epoch[34/60], MiniBatch[20/24], Loss: 2.22162, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[34/60], MiniBatch[4/4], Loss: 2.32375, Acc: 43.75000                \n",
      "Train epoch[35/60], MiniBatch[20/24], Loss: 2.24012, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[35/60], MiniBatch[4/4], Loss: 2.39576, Acc: 43.75000                \n",
      "Train epoch[36/60], MiniBatch[20/24], Loss: 2.21683, Acc: 27.00000, LR: 0.00000\n",
      "Eval epoch[36/60], MiniBatch[4/4], Loss: 2.40522, Acc: 43.75000                \n",
      "Train epoch[37/60], MiniBatch[20/24], Loss: 2.41149, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[37/60], MiniBatch[4/4], Loss: 1.94279, Acc: 43.75000                \n",
      "Train epoch[38/60], MiniBatch[20/24], Loss: 2.29092, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[38/60], MiniBatch[4/4], Loss: 2.45235, Acc: 43.75000                \n",
      "Train epoch[39/60], MiniBatch[20/24], Loss: 2.15922, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[39/60], MiniBatch[4/4], Loss: 1.94816, Acc: 43.75000                \n",
      "Train epoch[40/60], MiniBatch[20/24], Loss: 2.38511, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[40/60], MiniBatch[4/4], Loss: 2.45235, Acc: 43.75000                \n",
      "Train epoch[41/60], MiniBatch[20/24], Loss: 2.03550, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[41/60], MiniBatch[4/4], Loss: 2.45235, Acc: 43.75000                \n",
      "Train epoch[42/60], MiniBatch[20/24], Loss: 2.19199, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[42/60], MiniBatch[4/4], Loss: 2.48503, Acc: 43.75000                \n",
      "Train epoch[43/60], MiniBatch[20/24], Loss: 2.35373, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[43/60], MiniBatch[4/4], Loss: 1.94205, Acc: 43.75000                \n",
      "Train epoch[44/60], MiniBatch[20/24], Loss: 2.15519, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[44/60], MiniBatch[4/4], Loss: 2.39576, Acc: 43.75000                \n",
      "Train epoch[45/60], MiniBatch[20/24], Loss: 2.09206, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[45/60], MiniBatch[4/4], Loss: 2.39576, Acc: 43.75000                \n",
      "Train epoch[46/60], MiniBatch[20/24], Loss: 2.16036, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[46/60], MiniBatch[4/4], Loss: 1.94816, Acc: 43.75000                \n",
      "Train epoch[47/60], MiniBatch[20/24], Loss: 2.34172, Acc: 30.00000, LR: 0.00000\n",
      "Eval epoch[47/60], MiniBatch[4/4], Loss: 2.74285, Acc: 43.75000                \n",
      "Train epoch[48/60], MiniBatch[20/24], Loss: 2.27348, Acc: 27.00000, LR: 0.00000\n",
      "Eval epoch[48/60], MiniBatch[4/4], Loss: 2.40522, Acc: 43.75000                \n",
      "Train epoch[49/60], MiniBatch[20/24], Loss: 2.07619, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[49/60], MiniBatch[4/4], Loss: 2.32375, Acc: 43.75000                \n",
      "Train epoch[50/60], MiniBatch[20/24], Loss: 2.28821, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[50/60], MiniBatch[4/4], Loss: 2.38870, Acc: 43.75000                \n",
      "Train epoch[51/60], MiniBatch[20/24], Loss: 2.33074, Acc: 24.00000, LR: 0.00000\n",
      "Eval epoch[51/60], MiniBatch[4/4], Loss: 1.94279, Acc: 43.75000                \n",
      "Train epoch[52/60], MiniBatch[20/24], Loss: 2.30627, Acc: 25.00000, LR: 0.00000\n",
      "Eval epoch[52/60], MiniBatch[4/4], Loss: 2.19447, Acc: 43.75000                \n",
      "Train epoch[53/60], MiniBatch[20/24], Loss: 1.99851, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[53/60], MiniBatch[4/4], Loss: 2.32375, Acc: 43.75000                \n",
      "Train epoch[54/60], MiniBatch[20/24], Loss: 2.18234, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[54/60], MiniBatch[4/4], Loss: 2.39576, Acc: 43.75000                \n",
      "Train epoch[55/60], MiniBatch[20/24], Loss: 2.13819, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[55/60], MiniBatch[4/4], Loss: 1.94816, Acc: 43.75000                \n",
      "Train epoch[56/60], MiniBatch[20/24], Loss: 2.37456, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[56/60], MiniBatch[4/4], Loss: 2.39576, Acc: 43.75000                \n",
      "Train epoch[57/60], MiniBatch[20/24], Loss: 2.23082, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[57/60], MiniBatch[4/4], Loss: 1.94205, Acc: 43.75000                \n",
      "Train epoch[58/60], MiniBatch[20/24], Loss: 2.43580, Acc: 28.00000, LR: 0.00000\n",
      "Eval epoch[58/60], MiniBatch[4/4], Loss: 1.94466, Acc: 43.75000                \n",
      "Train epoch[59/60], MiniBatch[20/24], Loss: 2.36874, Acc: 29.00000, LR: 0.00000\n",
      "Eval epoch[59/60], MiniBatch[4/4], Loss: 1.88670, Acc: 43.75000                \n",
      "Train epoch[60/60], MiniBatch[20/24], Loss: 2.15330, Acc: 31.00000, LR: 0.00000\n",
      "Eval epoch[60/60], MiniBatch[4/4], Loss: 1.93725, Acc: 43.75000                \n"
     ]
    }
   ],
   "source": [
    "\n",
    "mymodel.train_model(network,epochs,dataloaders,optim,lr_sch,writer,stopp,checkpoint_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gpu_lr_conv_valid(model, epochs, dataloaders, optimiser, lr_scheduler):\n",
    "    msg = ''\n",
    "    for epoch in range(epochs):\n",
    "        ################ TRAINING ################\n",
    "        model.train()\n",
    "        train_dl = dataloaders[\"train\"]\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for batch_num, (motion_batch, label_batch) in enumerate(train_dl):\n",
    "            batch_sz = len(motion_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            motion_batch = motion_batch.to(DEVICE)\n",
    "            output = model(motion_batch)\n",
    "            losses = nn.CrossEntropyLoss()(output, label_batch)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            losses.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            preds_train = torch.argmax(output, dim=1)\n",
    "            correct_train += int(torch.eq(preds_train, label_batch).sum())\n",
    "            total_train +=batch_sz\n",
    "            minibatch_accuracy_train = 100 * correct_train / total_train\n",
    "\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_train}], Loss: {losses.item():.5f}, Acc: {minibatch_accuracy_train:.5f}, LR: {lr_scheduler.get_last_lr()[0]:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ##############################################################\n",
    "        print(\"\") # Create newline between progress bars\n",
    "        ##############################################################\n",
    "\n",
    "        model.eval()\n",
    "        val_dl = dataloaders[\"val\"]\n",
    "        total_val = len(val_dl)\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        for batch_num, (motion_batch, label_batch) in enumerate(val_dl):\n",
    "            batch_sz = len(motion_batch)\n",
    "            label_batch = label_batch.to(DEVICE)\n",
    "            motion_batch = motion_batch.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                output = model(motion_batch)\n",
    "                losses = nn.CrossEntropyLoss()(output, label_batch)\n",
    "                preds_val = torch.argmax(output, dim=1)\n",
    "                correct_val += int(torch.eq(preds_val, label_batch).sum())\n",
    "                total_val += batch_sz\n",
    "                minibatch_accuracy_val = 100 * correct_val / total_val\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            #if (batch_num + 1) % 5 == 0:\n",
    "            print(\" \" * len(msg), end='\\r')\n",
    "            msg = f'Val epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_val}], Loss: {losses.item():.5f}, Acc: {minibatch_accuracy_val:.5f}, LR: {lr_scheduler.get_last_lr()[0]:.5f}'\n",
    "            print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "     \n",
    "        ########################################################################\n",
    "        print(\"\")  # Create newline between progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[1/60], MiniBatch[20/100], Loss: 2.88297, Acc: 17.00000, LR: 0.00005\n",
      "Val epoch[1/60], MiniBatch[4/16], Loss: 1.82018, Acc: 6.25000, LR: 0.00003     \n",
      "Train epoch[2/60], MiniBatch[20/100], Loss: 2.47850, Acc: 11.00000, LR: 0.00003\n",
      "Val epoch[2/60], MiniBatch[4/16], Loss: 2.28179, Acc: 12.50000, LR: 0.00001    \n",
      "Train epoch[3/60], MiniBatch[20/100], Loss: 2.26144, Acc: 20.00000, LR: 0.00001\n",
      "Val epoch[3/60], MiniBatch[4/16], Loss: 2.10723, Acc: 12.50000, LR: 0.00001    \n",
      "Train epoch[4/60], MiniBatch[20/100], Loss: 2.37366, Acc: 22.00000, LR: 0.00001\n",
      "Val epoch[4/60], MiniBatch[4/16], Loss: 2.42516, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[5/60], MiniBatch[20/100], Loss: 2.19370, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[5/60], MiniBatch[4/16], Loss: 2.24689, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[6/60], MiniBatch[20/100], Loss: 2.08620, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[6/60], MiniBatch[4/16], Loss: 2.49619, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[7/60], MiniBatch[20/100], Loss: 2.17589, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[7/60], MiniBatch[4/16], Loss: 2.23682, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[8/60], MiniBatch[20/100], Loss: 2.17913, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[8/60], MiniBatch[4/16], Loss: 2.23005, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[9/60], MiniBatch[20/100], Loss: 1.98768, Acc: 19.00000, LR: 0.00000\n",
      "Val epoch[9/60], MiniBatch[4/16], Loss: 2.42538, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[10/60], MiniBatch[20/100], Loss: 2.25999, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[10/60], MiniBatch[4/16], Loss: 2.23321, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[11/60], MiniBatch[20/100], Loss: 2.35403, Acc: 23.00000, LR: 0.00000\n",
      "Val epoch[11/60], MiniBatch[4/16], Loss: 2.24756, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[12/60], MiniBatch[20/100], Loss: 2.35509, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[12/60], MiniBatch[4/16], Loss: 2.23416, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[13/60], MiniBatch[20/100], Loss: 2.29273, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[13/60], MiniBatch[4/16], Loss: 2.49466, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[14/60], MiniBatch[20/100], Loss: 2.41224, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[14/60], MiniBatch[4/16], Loss: 2.22983, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[15/60], MiniBatch[20/100], Loss: 2.56770, Acc: 18.00000, LR: 0.00000\n",
      "Val epoch[15/60], MiniBatch[4/16], Loss: 2.27400, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[16/60], MiniBatch[20/100], Loss: 2.28037, Acc: 19.00000, LR: 0.00000\n",
      "Val epoch[16/60], MiniBatch[4/16], Loss: 2.52827, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[17/60], MiniBatch[20/100], Loss: 2.46237, Acc: 19.00000, LR: 0.00000\n",
      "Val epoch[17/60], MiniBatch[4/16], Loss: 2.22990, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[18/60], MiniBatch[20/100], Loss: 2.01954, Acc: 24.00000, LR: 0.00000\n",
      "Val epoch[18/60], MiniBatch[4/16], Loss: 1.54070, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[19/60], MiniBatch[20/100], Loss: 2.23577, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[19/60], MiniBatch[4/16], Loss: 2.44885, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[20/60], MiniBatch[20/100], Loss: 2.44566, Acc: 15.00000, LR: 0.00000\n",
      "Val epoch[20/60], MiniBatch[4/16], Loss: 2.24753, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[21/60], MiniBatch[20/100], Loss: 2.21778, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[21/60], MiniBatch[4/16], Loss: 2.23845, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[22/60], MiniBatch[20/100], Loss: 2.26023, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[22/60], MiniBatch[4/16], Loss: 2.42408, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[23/60], MiniBatch[20/100], Loss: 2.18024, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[23/60], MiniBatch[4/16], Loss: 1.63871, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[24/60], MiniBatch[20/100], Loss: 2.17686, Acc: 18.00000, LR: 0.00000\n",
      "Val epoch[24/60], MiniBatch[4/16], Loss: 2.42408, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[25/60], MiniBatch[20/100], Loss: 1.99183, Acc: 23.00000, LR: 0.00000\n",
      "Val epoch[25/60], MiniBatch[4/16], Loss: 2.24753, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[26/60], MiniBatch[20/100], Loss: 2.12135, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[26/60], MiniBatch[4/16], Loss: 2.23845, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[27/60], MiniBatch[20/100], Loss: 2.13663, Acc: 23.00000, LR: 0.00000\n",
      "Val epoch[27/60], MiniBatch[4/16], Loss: 2.27400, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[28/60], MiniBatch[20/100], Loss: 2.09731, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[28/60], MiniBatch[4/16], Loss: 2.32998, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[29/60], MiniBatch[20/100], Loss: 2.18286, Acc: 23.00000, LR: 0.00000\n",
      "Val epoch[29/60], MiniBatch[4/16], Loss: 2.29569, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[30/60], MiniBatch[20/100], Loss: 2.12354, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[30/60], MiniBatch[4/16], Loss: 2.52826, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[31/60], MiniBatch[20/100], Loss: 1.97815, Acc: 24.00000, LR: 0.00000\n",
      "Val epoch[31/60], MiniBatch[4/16], Loss: 2.44885, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[32/60], MiniBatch[20/100], Loss: 2.30635, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[32/60], MiniBatch[4/16], Loss: 2.30796, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[33/60], MiniBatch[20/100], Loss: 2.18866, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[33/60], MiniBatch[4/16], Loss: 2.29569, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[34/60], MiniBatch[20/100], Loss: 2.05164, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[34/60], MiniBatch[4/16], Loss: 2.47199, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[35/60], MiniBatch[20/100], Loss: 2.19512, Acc: 18.00000, LR: 0.00000\n",
      "Val epoch[35/60], MiniBatch[4/16], Loss: 2.30796, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[36/60], MiniBatch[20/100], Loss: 2.09822, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[36/60], MiniBatch[4/16], Loss: 2.24753, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[37/60], MiniBatch[20/100], Loss: 2.23458, Acc: 23.00000, LR: 0.00000\n",
      "Val epoch[37/60], MiniBatch[4/16], Loss: 2.32998, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[38/60], MiniBatch[20/100], Loss: 2.41532, Acc: 22.00000, LR: 0.00000\n",
      "Val epoch[38/60], MiniBatch[4/16], Loss: 2.30796, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[39/60], MiniBatch[20/100], Loss: 2.42722, Acc: 20.00000, LR: 0.00000\n",
      "Val epoch[39/60], MiniBatch[4/16], Loss: 2.42408, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[40/60], MiniBatch[20/100], Loss: 2.34318, Acc: 19.00000, LR: 0.00000\n",
      "Val epoch[40/60], MiniBatch[4/16], Loss: 2.29493, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[41/60], MiniBatch[20/100], Loss: 2.36241, Acc: 21.00000, LR: 0.00000\n",
      "Val epoch[41/60], MiniBatch[4/16], Loss: 2.32998, Acc: 12.50000, LR: 0.00000    \n",
      "Train epoch[42/60], MiniBatch[5/25], Loss: 2.30916, Acc: 32.00000, LR: 0.00000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m network \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      9\u001b[0m \u001b[39m# call latest training function\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_model_gpu_lr_conv_valid(network,epochs,dataloaders,optim,lr_sch)\n",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m, in \u001b[0;36mtrain_model_gpu_lr_conv_valid\u001b[0;34m(model, epochs, dataloaders, optimiser, lr_scheduler)\u001b[0m\n\u001b[1;32m     19\u001b[0m optimiser\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m preds_train \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m correct_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(torch\u001b[39m.\u001b[39;49meq(preds_train, label_batch)\u001b[39m.\u001b[39;49msum())\n\u001b[1;32m     23\u001b[0m total_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39mbatch_sz\n\u001b[1;32m     24\u001b[0m minibatch_accuracy_train \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct_train \u001b[39m/\u001b[39m total_train\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# instantiate simple conv net\n",
    "network = get_simple_conv_net()\n",
    "# instantiate SGD optimiser\n",
    "optim = SGD(network.parameters(),lr = learning_rate)\n",
    "# instantiate exponential learning rate scheduler\n",
    "lr_sch = ExponentialLR(optim,gamma)\n",
    "# move model to DEVICE\n",
    "network = network.to(DEVICE)\n",
    "# call latest training function\n",
    "train_model_gpu_lr_conv_valid(network,epochs,dataloaders,optim,lr_sch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-envrionment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
