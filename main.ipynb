{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import Model.mymodel as mymodel\n",
    "import Model.trainer as trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 320, 240]         156,864\n",
      "         MaxPool2d-2         [-1, 64, 160, 120]               0\n",
      "       BatchNorm2d-3         [-1, 64, 160, 120]             128\n",
      "              ReLU-4         [-1, 64, 160, 120]               0\n",
      "            Conv2d-5         [-1, 64, 160, 120]          36,928\n",
      "       BatchNorm2d-6         [-1, 64, 160, 120]             128\n",
      "            Conv2d-7         [-1, 64, 160, 120]          36,928\n",
      "       BatchNorm2d-8         [-1, 64, 160, 120]             128\n",
      "          ResBlock-9         [-1, 64, 160, 120]               0\n",
      "           Conv2d-10         [-1, 64, 160, 120]          36,928\n",
      "      BatchNorm2d-11         [-1, 64, 160, 120]             128\n",
      "           Conv2d-12         [-1, 64, 160, 120]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 160, 120]             128\n",
      "         ResBlock-14         [-1, 64, 160, 120]               0\n",
      "           Conv2d-15          [-1, 128, 80, 60]           8,320\n",
      "      BatchNorm2d-16          [-1, 128, 80, 60]             256\n",
      "           Conv2d-17          [-1, 128, 80, 60]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 80, 60]             256\n",
      "           Conv2d-19          [-1, 128, 80, 60]         147,584\n",
      "      BatchNorm2d-20          [-1, 128, 80, 60]             256\n",
      "         ResBlock-21          [-1, 128, 80, 60]               0\n",
      "           Conv2d-22          [-1, 128, 80, 60]         147,584\n",
      "      BatchNorm2d-23          [-1, 128, 80, 60]             256\n",
      "           Conv2d-24          [-1, 128, 80, 60]         147,584\n",
      "      BatchNorm2d-25          [-1, 128, 80, 60]             256\n",
      "         ResBlock-26          [-1, 128, 80, 60]               0\n",
      "           Conv2d-27          [-1, 256, 40, 30]          33,024\n",
      "      BatchNorm2d-28          [-1, 256, 40, 30]             512\n",
      "           Conv2d-29          [-1, 256, 40, 30]         295,168\n",
      "      BatchNorm2d-30          [-1, 256, 40, 30]             512\n",
      "           Conv2d-31          [-1, 256, 40, 30]         590,080\n",
      "      BatchNorm2d-32          [-1, 256, 40, 30]             512\n",
      "         ResBlock-33          [-1, 256, 40, 30]               0\n",
      "           Conv2d-34          [-1, 256, 40, 30]         590,080\n",
      "      BatchNorm2d-35          [-1, 256, 40, 30]             512\n",
      "           Conv2d-36          [-1, 256, 40, 30]         590,080\n",
      "      BatchNorm2d-37          [-1, 256, 40, 30]             512\n",
      "         ResBlock-38          [-1, 256, 40, 30]               0\n",
      "           Conv2d-39          [-1, 512, 20, 15]         131,584\n",
      "      BatchNorm2d-40          [-1, 512, 20, 15]           1,024\n",
      "           Conv2d-41          [-1, 512, 20, 15]       1,180,160\n",
      "      BatchNorm2d-42          [-1, 512, 20, 15]           1,024\n",
      "           Conv2d-43          [-1, 512, 20, 15]       2,359,808\n",
      "      BatchNorm2d-44          [-1, 512, 20, 15]           1,024\n",
      "         ResBlock-45          [-1, 512, 20, 15]               0\n",
      "           Conv2d-46          [-1, 512, 20, 15]       2,359,808\n",
      "      BatchNorm2d-47          [-1, 512, 20, 15]           1,024\n",
      "           Conv2d-48          [-1, 512, 20, 15]       2,359,808\n",
      "      BatchNorm2d-49          [-1, 512, 20, 15]           1,024\n",
      "         ResBlock-50          [-1, 512, 20, 15]               0\n",
      "AdaptiveAvgPool2d-51            [-1, 512, 1, 1]               0\n",
      "          Flatten-52                  [-1, 512]               0\n",
      "           Linear-53                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,333,834\n",
      "Trainable params: 11,333,834\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 58.59\n",
      "Forward/backward pass size (MB): 257.82\n",
      "Params size (MB): 43.24\n",
      "Estimated Total Size (MB): 359.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "set_frame = 50\n",
    "\n",
    "epochs = 60\n",
    "batch_sz = 10\n",
    "checkpoint_frequency = 5\n",
    "learning_rate = 0.0005\n",
    "gamma = 0.8\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dl, val_dl, test_dl = trainer.load_data()\n",
    "\n",
    "dataloaders = {\n",
    "    'train' : train_dl,\n",
    "    'val' : val_dl,\n",
    "    'test' : test_dl\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "network = trainer.get_resnet()\n",
    "network = network.to(DEVICE)\n",
    "\n",
    "optim = SGD(network.parameters(), lr=learning_rate)\n",
    "lr_sch = ExponentialLR(optim, gamma)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "stopp = trainer.EarlyStopper(patience = 5, tolerance = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[1/60], MiniBatch[24/24], Loss: 2.10820, Acc: 8.62069, LR: 0.00050\n",
      "Eval epoch[1/60], MiniBatch[4/4], Loss: 2.66172, Acc: 18.75000               \n",
      "Train epoch[2/60], MiniBatch[24/24], Loss: 2.45904, Acc: 25.86207, LR: 0.00040\n",
      "Eval epoch[2/60], MiniBatch[4/4], Loss: 2.28330, Acc: 18.75000                \n",
      "Train epoch[3/60], MiniBatch[24/24], Loss: 1.77769, Acc: 22.41379, LR: 0.00032\n",
      "Eval epoch[3/60], MiniBatch[4/4], Loss: 1.64095, Acc: 18.75000                \n",
      "Train epoch[4/60], MiniBatch[24/24], Loss: 2.47501, Acc: 22.41379, LR: 0.00026\n",
      "Eval epoch[4/60], MiniBatch[4/4], Loss: 2.26488, Acc: 18.75000                \n",
      "Train epoch[5/60], MiniBatch[24/24], Loss: 1.69814, Acc: 25.00000, LR: 0.00020\n",
      "Eval epoch[5/60], MiniBatch[4/4], Loss: 2.39592, Acc: 18.75000                \n",
      "Train epoch[6/60], MiniBatch[24/24], Loss: 2.33039, Acc: 27.58621, LR: 0.00016\n",
      "Eval epoch[6/60], MiniBatch[4/4], Loss: 2.60015, Acc: 18.75000                \n",
      "Train epoch[7/60], MiniBatch[24/24], Loss: 2.64386, Acc: 25.00000, LR: 0.00013\n",
      "Eval epoch[7/60], MiniBatch[4/4], Loss: 2.51600, Acc: 18.75000                \n",
      "Train epoch[8/60], MiniBatch[24/24], Loss: 2.63654, Acc: 27.58621, LR: 0.00010\n",
      "Eval epoch[8/60], MiniBatch[4/4], Loss: 2.57220, Acc: 18.75000                \n",
      "Train epoch[9/60], MiniBatch[24/24], Loss: 2.44736, Acc: 30.17241, LR: 0.00008\n",
      "Eval epoch[9/60], MiniBatch[4/4], Loss: 1.95521, Acc: 18.75000                \n",
      "Train epoch[10/60], MiniBatch[24/24], Loss: 2.22777, Acc: 28.44828, LR: 0.00007\n",
      "Eval epoch[10/60], MiniBatch[4/4], Loss: 2.58443, Acc: 18.75000                \n",
      "Train epoch[11/60], MiniBatch[24/24], Loss: 2.35201, Acc: 26.72414, LR: 0.00005\n",
      "Eval epoch[11/60], MiniBatch[4/4], Loss: 1.61180, Acc: 18.75000                \n",
      "Train epoch[12/60], MiniBatch[24/24], Loss: 2.22283, Acc: 29.31034, LR: 0.00004\n",
      "Eval epoch[12/60], MiniBatch[4/4], Loss: 1.58896, Acc: 18.75000                \n",
      "Train epoch[13/60], MiniBatch[24/24], Loss: 1.71093, Acc: 28.44828, LR: 0.00003\n",
      "Eval epoch[13/60], MiniBatch[4/4], Loss: 2.56442, Acc: 18.75000                \n",
      "Train epoch[14/60], MiniBatch[24/24], Loss: 2.33670, Acc: 28.44828, LR: 0.00003\n",
      "Eval epoch[14/60], MiniBatch[4/4], Loss: 2.53592, Acc: 18.75000                \n",
      "Train epoch[15/60], MiniBatch[24/24], Loss: 2.45684, Acc: 30.17241, LR: 0.00002\n",
      "Eval epoch[15/60], MiniBatch[4/4], Loss: 1.60035, Acc: 18.75000                \n",
      "Train epoch[16/60], MiniBatch[24/24], Loss: 2.58679, Acc: 29.31034, LR: 0.00002\n",
      "Eval epoch[16/60], MiniBatch[4/4], Loss: 2.56447, Acc: 18.75000                \n",
      "Train epoch[17/60], MiniBatch[24/24], Loss: 1.69166, Acc: 29.31034, LR: 0.00001\n",
      "Eval epoch[17/60], MiniBatch[4/4], Loss: 2.58972, Acc: 18.75000                \n",
      "Train epoch[18/60], MiniBatch[24/24], Loss: 2.64780, Acc: 28.44828, LR: 0.00001\n",
      "Eval epoch[18/60], MiniBatch[4/4], Loss: 2.57726, Acc: 18.75000                \n",
      "Train epoch[19/60], MiniBatch[24/24], Loss: 2.59686, Acc: 29.31034, LR: 0.00001\n",
      "Eval epoch[19/60], MiniBatch[4/4], Loss: 1.58665, Acc: 18.75000                \n",
      "Train epoch[20/60], MiniBatch[24/24], Loss: 2.41191, Acc: 28.44828, LR: 0.00001\n",
      "Eval epoch[20/60], MiniBatch[4/4], Loss: 1.87791, Acc: 18.75000                \n",
      "Train epoch[21/60], MiniBatch[24/24], Loss: 1.70879, Acc: 29.31034, LR: 0.00001\n",
      "Eval epoch[21/60], MiniBatch[4/4], Loss: 2.58812, Acc: 18.75000                \n",
      "Train epoch[22/60], MiniBatch[24/24], Loss: 2.05977, Acc: 25.86207, LR: 0.00000\n",
      "Eval epoch[22/60], MiniBatch[4/4], Loss: 2.57193, Acc: 18.75000                \n",
      "Train epoch[23/60], MiniBatch[24/24], Loss: 1.69223, Acc: 26.72414, LR: 0.00000\n",
      "Eval epoch[23/60], MiniBatch[4/4], Loss: 2.62703, Acc: 18.75000                \n",
      "Train epoch[24/60], MiniBatch[24/24], Loss: 2.36587, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[24/60], MiniBatch[4/4], Loss: 2.23368, Acc: 18.75000                \n",
      "Train epoch[25/60], MiniBatch[24/24], Loss: 2.35088, Acc: 26.72414, LR: 0.00000\n",
      "Eval epoch[25/60], MiniBatch[4/4], Loss: 2.54947, Acc: 18.75000                \n",
      "Train epoch[26/60], MiniBatch[24/24], Loss: 2.64383, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[26/60], MiniBatch[4/4], Loss: 2.58885, Acc: 18.75000                \n",
      "Train epoch[27/60], MiniBatch[24/24], Loss: 2.63031, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[27/60], MiniBatch[4/4], Loss: 2.59360, Acc: 18.75000                \n",
      "Train epoch[28/60], MiniBatch[24/24], Loss: 2.56013, Acc: 25.86207, LR: 0.00000\n",
      "Eval epoch[28/60], MiniBatch[4/4], Loss: 1.58873, Acc: 18.75000                \n",
      "Train epoch[29/60], MiniBatch[24/24], Loss: 2.09192, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[29/60], MiniBatch[4/4], Loss: 1.54895, Acc: 18.75000                \n",
      "Train epoch[30/60], MiniBatch[24/24], Loss: 2.21462, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[30/60], MiniBatch[4/4], Loss: 2.22698, Acc: 18.75000                \n",
      "Train epoch[31/60], MiniBatch[24/24], Loss: 2.58115, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[31/60], MiniBatch[4/4], Loss: 2.58837, Acc: 18.75000                \n",
      "Train epoch[32/60], MiniBatch[24/24], Loss: 2.42452, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[32/60], MiniBatch[4/4], Loss: 2.56402, Acc: 18.75000                \n",
      "Train epoch[33/60], MiniBatch[24/24], Loss: 2.18989, Acc: 30.17241, LR: 0.00000\n",
      "Eval epoch[33/60], MiniBatch[4/4], Loss: 2.38735, Acc: 18.75000                \n",
      "Train epoch[34/60], MiniBatch[24/24], Loss: 2.05669, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[34/60], MiniBatch[4/4], Loss: 2.31019, Acc: 18.75000                \n",
      "Train epoch[35/60], MiniBatch[24/24], Loss: 2.05657, Acc: 25.86207, LR: 0.00000\n",
      "Eval epoch[35/60], MiniBatch[4/4], Loss: 2.54234, Acc: 18.75000                \n",
      "Train epoch[36/60], MiniBatch[24/24], Loss: 2.17050, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[36/60], MiniBatch[4/4], Loss: 2.21012, Acc: 18.75000                \n",
      "Train epoch[37/60], MiniBatch[24/24], Loss: 2.61106, Acc: 30.17241, LR: 0.00000\n",
      "Eval epoch[37/60], MiniBatch[4/4], Loss: 2.63316, Acc: 18.75000                \n",
      "Train epoch[38/60], MiniBatch[24/24], Loss: 2.57208, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[38/60], MiniBatch[4/4], Loss: 1.85723, Acc: 18.75000                \n",
      "Train epoch[39/60], MiniBatch[24/24], Loss: 2.62432, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[39/60], MiniBatch[4/4], Loss: 1.60216, Acc: 18.75000                \n",
      "Train epoch[40/60], MiniBatch[24/24], Loss: 2.62979, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[40/60], MiniBatch[4/4], Loss: 2.62048, Acc: 18.75000                \n",
      "Train epoch[41/60], MiniBatch[24/24], Loss: 2.61198, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[41/60], MiniBatch[4/4], Loss: 1.61880, Acc: 18.75000                \n",
      "Train epoch[42/60], MiniBatch[24/24], Loss: 1.68350, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[42/60], MiniBatch[4/4], Loss: 2.39157, Acc: 18.75000                \n",
      "Train epoch[43/60], MiniBatch[24/24], Loss: 2.43133, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[43/60], MiniBatch[4/4], Loss: 2.55801, Acc: 18.75000                \n",
      "Train epoch[44/60], MiniBatch[24/24], Loss: 2.33927, Acc: 26.72414, LR: 0.00000\n",
      "Eval epoch[44/60], MiniBatch[4/4], Loss: 2.62946, Acc: 18.75000                \n",
      "Train epoch[45/60], MiniBatch[24/24], Loss: 2.41068, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[45/60], MiniBatch[4/4], Loss: 2.59147, Acc: 18.75000                \n",
      "Train epoch[46/60], MiniBatch[24/24], Loss: 1.69022, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[46/60], MiniBatch[4/4], Loss: 2.30446, Acc: 18.75000                \n",
      "Train epoch[47/60], MiniBatch[24/24], Loss: 2.32888, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[47/60], MiniBatch[4/4], Loss: 2.38865, Acc: 18.75000                \n",
      "Train epoch[48/60], MiniBatch[24/24], Loss: 2.64773, Acc: 30.17241, LR: 0.00000\n",
      "Eval epoch[48/60], MiniBatch[4/4], Loss: 1.82986, Acc: 18.75000                \n",
      "Train epoch[49/60], MiniBatch[24/24], Loss: 2.58544, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[49/60], MiniBatch[4/4], Loss: 2.62912, Acc: 18.75000                \n",
      "Train epoch[50/60], MiniBatch[24/24], Loss: 2.58061, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[50/60], MiniBatch[4/4], Loss: 1.73235, Acc: 18.75000                \n",
      "Train epoch[51/60], MiniBatch[24/24], Loss: 1.69533, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[51/60], MiniBatch[4/4], Loss: 2.56765, Acc: 18.75000                \n",
      "Train epoch[52/60], MiniBatch[24/24], Loss: 2.32373, Acc: 26.72414, LR: 0.00000\n",
      "Eval epoch[52/60], MiniBatch[4/4], Loss: 1.60623, Acc: 18.75000                \n",
      "Train epoch[53/60], MiniBatch[24/24], Loss: 2.45573, Acc: 27.58621, LR: 0.00000\n",
      "Eval epoch[53/60], MiniBatch[4/4], Loss: 2.58801, Acc: 18.75000                \n",
      "Train epoch[54/60], MiniBatch[24/24], Loss: 2.18964, Acc: 31.03448, LR: 0.00000\n",
      "Eval epoch[54/60], MiniBatch[4/4], Loss: 2.53542, Acc: 18.75000                \n",
      "Train epoch[55/60], MiniBatch[24/24], Loss: 2.42438, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[55/60], MiniBatch[4/4], Loss: 2.59481, Acc: 18.75000                \n",
      "Train epoch[56/60], MiniBatch[24/24], Loss: 1.69865, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[56/60], MiniBatch[4/4], Loss: 1.87250, Acc: 18.75000                \n",
      "Train epoch[57/60], MiniBatch[24/24], Loss: 2.18015, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[57/60], MiniBatch[4/4], Loss: 2.58905, Acc: 18.75000                \n",
      "Train epoch[58/60], MiniBatch[24/24], Loss: 2.58545, Acc: 28.44828, LR: 0.00000\n",
      "Eval epoch[58/60], MiniBatch[4/4], Loss: 2.58593, Acc: 18.75000                \n",
      "Train epoch[59/60], MiniBatch[24/24], Loss: 2.07846, Acc: 25.86207, LR: 0.00000\n",
      "Eval epoch[59/60], MiniBatch[4/4], Loss: 1.55903, Acc: 18.75000                \n",
      "Train epoch[60/60], MiniBatch[24/24], Loss: 2.06486, Acc: 29.31034, LR: 0.00000\n",
      "Eval epoch[60/60], MiniBatch[4/4], Loss: 2.57901, Acc: 18.75000                \n"
     ]
    }
   ],
   "source": [
    "writer = trainer.train_model(network,epochs,dataloaders,optim,lr_sch,writer,stopp,checkpoint_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-envrionment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
