{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BandaiDataset as bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./saved_models\"\n",
    "DATASET_DIR = \"./datasets/data/\"\n",
    "FILELIST_PATH = \"datafiles.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bd.BandaiDataset(FILELIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "set_frame = 50\n",
    "def custom_collate_fn(batch):\n",
    "    motion_batch_tensor = torch.FloatTensor(len(batch),50,480,640)\n",
    "    motion_tensors = []\n",
    "    labels = []\n",
    "    #print(type(batch))\n",
    "\n",
    "    for item in batch:\n",
    "        #print(item)\n",
    "        motion_tensor = item.get_motion_tensor(50) # load an motion as a tensor(frames,width,height)\n",
    "        motion_tensors.append(motion_tensor.unsqueeze(0)) # put motions into a list : to be checked \n",
    "        labels.append(item.label)\n",
    "\n",
    "    torch.cat(motion_tensors, out=motion_batch_tensor)\n",
    "    label_batch_tensor = torch.LongTensor(labels)\n",
    "    return (motion_batch_tensor,label_batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import multiprocessing as mp\n",
    "\n",
    "def load_data(file_list_path= '', data_path='', batch_sz = 5, train_val_test_split = [0.7,0.1,0.2]):\n",
    "    assert sum(train_val_test_split) == 1, \"Train, val and test fractions should sum to 1!\" \n",
    "    dataset = bd.BandaiDataset(data_path)\n",
    "    dataset.load()\n",
    "\n",
    "    tr_va_te = []\n",
    "    n_cpus = mp.cpu_count()\n",
    "    \n",
    "    for frac in train_val_test_split:\n",
    "        num = round(frac * dataset.num_of_files)\n",
    "        tr_va_te.append(num)\n",
    "    \n",
    "    if tr_va_te[0] != (dataset.num_of_files - tr_va_te[1] - tr_va_te[2]):\n",
    "        tr_va_te[0] = (dataset.num_of_files - tr_va_te[1] - tr_va_te[2])\n",
    "    \n",
    "    #assert 1==2, f\"tr_va_te = {tr_va_te}\"\n",
    "\n",
    "    train_split, val_split, test_split = random_split(dataset, tr_va_te)\n",
    "\n",
    "    train_dl = DataLoader(train_split,\n",
    "                          batch_size=batch_sz,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=custom_collate_fn,\n",
    "                          num_workers=n_cpus\n",
    "                        )\n",
    "    val_dl = DataLoader(val_split,\n",
    "                        batch_size=batch_sz,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=custom_collate_fn,\n",
    "                        num_workers=n_cpus)\n",
    "    test_dl = DataLoader(test_split,\n",
    "                         batch_size=batch_sz,\n",
    "                         shuffle=True,\n",
    "                         collate_fn=custom_collate_fn,\n",
    "                         num_workers=n_cpus)\n",
    "\n",
    "    return train_dl, val_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_motions, _ = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_motions,test_labels = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor (motion_batch,label_batch) in train_dl:\\n    batch_sz = len(motion_batch)\\n    print(batch_sz)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for (motion_batch,label_batch) in train_dl:\n",
    "    batch_sz = len(motion_batch)\n",
    "    print(batch_sz)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307200\n",
      "227\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n",
      "307200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.size(dataset[164].pose_list[0]))\n",
    "print(dataset[164].frame_num)\n",
    "#tensor = np.array(dataset[54].pose_list)\n",
    "for pose in dataset[54].pose_list:\n",
    "    print(np.size(pose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "dataset-1_walk_tired_002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset.filelist))\n",
    "print(dataset.filelist[164])\n",
    "dataset.num_of_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 129 ->{50}\n",
      "1: 91 ->{50}\n",
      "2: 99 ->{50}\n",
      "3: 118 ->{50}\n",
      "4: 219 ->{50}\n",
      "5: 123 ->{50}\n",
      "6: 139 ->{50}\n",
      "7: 71 ->{50}\n",
      "8: 157 ->{50}\n",
      "9: 139 ->{50}\n",
      "10: 146 ->{50}\n",
      "11: 173 ->{50}\n",
      "12: 138 ->{50}\n",
      "13: 222 ->{50}\n",
      "14: 166 ->{50}\n",
      "15: 230 ->{50}\n",
      "16: 56 ->{50}\n",
      "17: 170 ->{50}\n",
      "18: 150 ->{50}\n",
      "19: 85 ->{50}\n",
      "20: 236 ->{50}\n",
      "21: 221 ->{50}\n",
      "22: 202 ->{50}\n",
      "23: 158 ->{50}\n",
      "24: 122 ->{50}\n",
      "25: 141 ->{50}\n",
      "26: 123 ->{50}\n",
      "27: 80 ->{50}\n",
      "28: 235 ->{50}\n",
      "29: 304 ->{50}\n",
      "30: 186 ->{50}\n",
      "31: 111 ->{50}\n",
      "32: 124 ->{50}\n",
      "33: 131 ->{50}\n",
      "34: 329 ->{50}\n",
      "35: 143 ->{50}\n",
      "36: 224 ->{50}\n",
      "37: 213 ->{50}\n",
      "38: 188 ->{50}\n",
      "39: 112 ->{50}\n",
      "40: 209 ->{50}\n",
      "41: 142 ->{50}\n",
      "42: 174 ->{50}\n",
      "43: 254 ->{50}\n",
      "44: 211 ->{50}\n",
      "45: 86 ->{50}\n",
      "46: 75 ->{50}\n",
      "47: 76 ->{50}\n",
      "48: 70 ->{50}\n",
      "49: 98 ->{50}\n",
      "50: 68 ->{50}\n",
      "51: 118 ->{50}\n",
      "52: 71 ->{50}\n",
      "53: 68 ->{50}\n",
      "54: 21 ->{50}\n",
      "55: 100 ->{50}\n",
      "56: 86 ->{50}\n",
      "57: 106 ->{50}\n",
      "58: 82 ->{50}\n",
      "59: 94 ->{50}\n",
      "60: 141 ->{50}\n",
      "61: 111 ->{50}\n",
      "62: 120 ->{50}\n",
      "63: 187 ->{50}\n",
      "64: 301 ->{50}\n",
      "65: 164 ->{50}\n",
      "66: 106 ->{50}\n",
      "67: 153 ->{50}\n",
      "68: 201 ->{50}\n",
      "69: 87 ->{50}\n",
      "70: 163 ->{50}\n",
      "71: 216 ->{50}\n",
      "72: 114 ->{50}\n",
      "73: 164 ->{50}\n",
      "74: 83 ->{50}\n",
      "75: 73 ->{50}\n",
      "76: 78 ->{50}\n",
      "77: 112 ->{50}\n",
      "78: 71 ->{50}\n",
      "79: 121 ->{50}\n",
      "80: 80 ->{50}\n",
      "81: 141 ->{50}\n",
      "82: 60 ->{50}\n",
      "83: 73 ->{50}\n",
      "84: 25 ->{50}\n",
      "85: 142 ->{50}\n",
      "86: 103 ->{50}\n",
      "87: 142 ->{50}\n",
      "88: 142 ->{50}\n",
      "89: 134 ->{50}\n",
      "90: 208 ->{50}\n",
      "91: 257 ->{50}\n",
      "92: 241 ->{50}\n",
      "93: 187 ->{50}\n",
      "94: 316 ->{50}\n",
      "95: 237 ->{50}\n",
      "96: 216 ->{50}\n",
      "97: 184 ->{50}\n",
      "98: 201 ->{50}\n",
      "99: 32 ->{50}\n",
      "100: 365 ->{50}\n",
      "101: 283 ->{50}\n",
      "102: 392 ->{50}\n",
      "103: 393 ->{50}\n",
      "104: 218 ->{50}\n",
      "105: 91 ->{50}\n",
      "106: 152 ->{50}\n",
      "107: 132 ->{50}\n",
      "108: 119 ->{50}\n",
      "109: 218 ->{50}\n",
      "110: 118 ->{50}\n",
      "111: 150 ->{50}\n",
      "112: 105 ->{50}\n",
      "113: 148 ->{50}\n",
      "114: 136 ->{50}\n",
      "115: 243 ->{50}\n",
      "116: 157 ->{50}\n",
      "117: 204 ->{50}\n",
      "118: 335 ->{50}\n",
      "119: 139 ->{50}\n",
      "120: 91 ->{50}\n",
      "121: 153 ->{50}\n",
      "122: 138 ->{50}\n",
      "123: 119 ->{50}\n",
      "124: 222 ->{50}\n",
      "125: 156 ->{50}\n",
      "126: 153 ->{50}\n",
      "127: 103 ->{50}\n",
      "128: 149 ->{50}\n",
      "129: 136 ->{50}\n",
      "130: 243 ->{50}\n",
      "131: 137 ->{50}\n",
      "132: 265 ->{50}\n",
      "133: 290 ->{50}\n",
      "134: 135 ->{50}\n",
      "135: 147 ->{50}\n",
      "136: 146 ->{50}\n",
      "137: 144 ->{50}\n",
      "138: 243 ->{50}\n",
      "139: 236 ->{50}\n",
      "140: 227 ->{50}\n",
      "141: 171 ->{50}\n",
      "142: 185 ->{50}\n",
      "143: 278 ->{50}\n",
      "144: 211 ->{50}\n",
      "145: 195 ->{50}\n",
      "146: 223 ->{50}\n",
      "147: 214 ->{50}\n",
      "148: 136 ->{50}\n",
      "149: 166 ->{50}\n",
      "150: 187 ->{50}\n",
      "151: 269 ->{50}\n",
      "152: 192 ->{50}\n",
      "153: 196 ->{50}\n",
      "154: 32 ->{50}\n",
      "155: 482 ->{50}\n",
      "156: 172 ->{50}\n",
      "157: 286 ->{50}\n",
      "158: 296 ->{50}\n",
      "159: 332 ->{50}\n",
      "160: 305 ->{50}\n",
      "161: 348 ->{50}\n",
      "162: 412 ->{50}\n",
      "163: 248 ->{50}\n",
      "164: 227 ->{50}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,165):\n",
    "    print(f'{i}: {dataset[i].frame_num} ->' ,end='')\n",
    "    tensor = dataset[i].get_motion_tensor(50)\n",
    "    print({dataset[i].frame_num},flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics.classification as tmcls \n",
    "class ClassifierMetrics(object):\n",
    "    ap: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    acc: float\n",
    "    count: int\n",
    "\n",
    "    def __init__(self, task, n_labels, device):\n",
    "        self.task = task\n",
    "        if self.task == \"multiclass\":\n",
    "            self.ap_metric = tmcls.MulticlassAveragePrecision(num_classes=n_labels, average=None, thresholds=None).to(device)\n",
    "            self.precision_metric = tmcls.MulticlassPrecision(num_classes=n_labels).to(device)\n",
    "            self.recall_metric = tmcls.MulticlassRecall(num_classes=n_labels).to(device)\n",
    "            self.f1_metric = tmcls.MulticlassF1Score(num_classes=n_labels).to(device)\n",
    "            self.acc_metric = tmcls.MulticlassAccuracy(num_classes=n_labels).to(device)\n",
    "\n",
    "        elif self.task == \"multilabel\":\n",
    "            self.ap_metric = tmcls.MultilabelAveragePrecision(num_labels=n_labels, average=None, thresholds=None).to(device)\n",
    "            self.precision_metric = tmcls.MultilabelPrecision(num_labels=n_labels).to(device)\n",
    "            self.recall_metric = tmcls.MultilabelRecall(num_labels=n_labels).to(device)\n",
    "            self.f1_metric = tmcls.MultilabelF1Score(num_labels=n_labels).to(device)\n",
    "            self.acc_metric = tmcls.MultilabelAccuracy(task=self.task, num_labels=n_labels).to(device)\n",
    "        self.reset()\n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        self.ap = 0\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "        self.f1 = 0\n",
    "        self.acc = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, y_pred, y):\n",
    "        y = y.long()\n",
    "        self.ap += self.ap_metric(y_pred, y)\n",
    "        self.precision += self.precision_metric(y_pred, y)\n",
    "        self.recall += self.recall_metric(y_pred, y)\n",
    "        self.f1 += self.f1_metric(y_pred, y)\n",
    "        self.acc += self.acc_metric(y_pred, y)\n",
    "        self.count += 1 #y.size(0)\n",
    "\n",
    "    def calc(self, y_pred, y):\n",
    "        self.reset()\n",
    "        y = y.long()\n",
    "        self.ap = self.ap_metric(y_pred, y)\n",
    "        self.precision = self.precision_metric(y_pred, y)\n",
    "        self.recall = self.recall_metric(y_pred, y)\n",
    "        self.f1 = self.f1_metric(y_pred, y)\n",
    "\n",
    "    def avg(self):\n",
    "        self.ap = self.ap / self.count\n",
    "        self.precision = self.precision / self.count\n",
    "        self.recall = self.recall / self.count\n",
    "        self.f1 = self.f1 / self.count\n",
    "        self.acc = self.acc / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x240000 and 960000x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_simple_conv_net\u001b[39m():\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m ConvNet()\n\u001b[0;32m---> 63\u001b[0m summary(get_simple_conv_net(), input_size\u001b[39m=\u001b[39;49m(\u001b[39m50\u001b[39;49m, \u001b[39m640\u001b[39;49m, \u001b[39m480\u001b[39;49m), device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 50\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     45\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool3(inp)\n\u001b[1;32m     48\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat(inp)\n\u001b[0;32m---> 50\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1 (inp) \n\u001b[1;32m     51\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu4(inp)            \n\u001b[1;32m     52\u001b[0m inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(inp) \n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1569\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[39m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/assignment-envrionment/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x240000 and 960000x128)"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=5, stride=1, padding=2) #[(dimension_sz−kernel+2*Padding)/Stride]+1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=5, stride=1, padding=2) #[(dimension_sz−kernel+2*Padding)/Stride]+1\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)  \n",
    "##########\n",
    "        '''\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=5, stride=1, padding=2) #[(dimension_sz−kernel+2*Padding)/Stride]+1\n",
    "        self.relu3 = nn.ReLU()\n",
    "        '''\n",
    "        #self.pool3 = nn.MaxPool2d(kernel_size=2)  \n",
    "        \n",
    "        self.flat = nn.Flatten()            \n",
    "        self.fc1 = nn.Linear(50 * 160 * 120, 128)   \n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.relu6 = nn.ReLU()\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = self.conv1(inp)\n",
    "        inp = self.relu1(inp) \n",
    "        inp = self.pool1(inp)\n",
    "\n",
    "        inp = self.conv2(inp)\n",
    "        inp = self.relu2(inp) \n",
    "        inp = self.pool2(inp)\n",
    "        '''\n",
    "        inp = self.conv3(inp)\n",
    "        inp = self.relu3(inp) \n",
    "        '''\n",
    "        inp = self.pool3(inp)\n",
    "        \n",
    "\n",
    "        inp = self.flat(inp)\n",
    "\n",
    "        inp = self.fc1 (inp) \n",
    "        inp = self.relu4(inp)            \n",
    "        inp = self.fc2(inp) \n",
    "        inp = self.relu5(inp)\n",
    "        inp = self.fc3(inp) \n",
    "        inp = self.relu6(inp)\n",
    "        out = self.fc4(inp)\n",
    "        return out\n",
    "    \n",
    "\n",
    "def get_simple_conv_net():\n",
    "    return ConvNet()\n",
    "\n",
    "summary(get_simple_conv_net(), input_size=(50, 640, 480), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,epochs,train_dl,optimiser, device):\n",
    "    msg = \"\"\n",
    "    for epoch in range (epochs):\n",
    "        total_steps = len(train_dl)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "        for batch_num, (motion_batch, label_batch) in enumerate(train_dl):\n",
    "            batch_sz = len(motion_batch)\n",
    "            motion_batch  = motion_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            output = model(motion_batch)\n",
    "            losses = nn.CrossEntropyLoss()(output, label_batch)\n",
    "            optimiser.zero_grad()\n",
    "            losses.backward\n",
    "            optimiser.step()\n",
    "\n",
    "            preds = torch.argmax(output,dim=1)\n",
    "            correct += int(torch.eq(preds,label_batch).sum())\n",
    "            total += batch_sz\n",
    "            minibatch_accuracy = 100 * correct/total\n",
    "\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "            if (batch_num + 1) % 5 == 0:\n",
    "                print(\" \" * len(msg), end='\\r')\n",
    "                msg = f'Train epoch[{epoch+1}/{epochs}], MiniBatch[{batch_num + 1}/{total_steps}], Loss: {losses.item():.5f}, Acc: {minibatch_accuracy:.5f}'\n",
    "                print (msg, end='\\r' if epoch < epochs else \"\\n\",flush=True)\n",
    "            #### Fancy printing stuff, you can ignore this! ######\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "epochs = 50\n",
    "batch_sz = 16\n",
    "learning_rate = 0.00005\n",
    "train_dl, val_dl, test_dl = load_data(batch_sz=batch_sz)\n",
    "network = get_simple_conv_net().to(DEVICE)\n",
    "optim = SGD(network.parameters(),lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch[50/50], MiniBatch[5/8], Loss: 2.31804, Acc: 10.00000\r"
     ]
    }
   ],
   "source": [
    "train_model(network,epochs,train_dl,optim, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-envrionment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
