{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BandaiDataset as bd\n",
    "\n",
    "data = bd.BandaiDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-1_bow_active_001: stream end\n",
      "dataset-1_bow_angry_001: stream end\n",
      "dataset-1_bow_childish_001: stream end\n",
      "dataset-1_bow_chimpira_001: stream end\n",
      "dataset-1_bow_feminine_001: stream end\n",
      "dataset-1_bow_giant_001: stream end\n",
      "dataset-1_bow_happy_001: stream end\n",
      "dataset-1_bow_masculinity_001: stream end\n",
      "dataset-1_bow_musical_001: stream end\n",
      "dataset-1_bow_normal_001: stream end\n",
      "dataset-1_bow_not-confident_001: stream end\n",
      "dataset-1_bow_old_001: stream end\n",
      "dataset-1_bow_proud_001: stream end\n",
      "dataset-1_bow_sad_001: stream end\n",
      "dataset-1_bow_tired_001: stream end\n",
      "dataset-1_byebye_active_001: stream end\n",
      "dataset-1_byebye_angry_001: stream end\n",
      "dataset-1_byebye_childish_001: stream end\n",
      "dataset-1_byebye_chimpira_001: stream end\n",
      "dataset-1_byebye_feminine_001: stream end\n",
      "dataset-1_byebye_giant_001: stream end\n",
      "dataset-1_byebye_happy_001: stream end\n",
      "dataset-1_byebye_masculinity_001: stream end\n",
      "dataset-1_byebye_musical_001: stream end\n",
      "dataset-1_byebye_normal_001: stream end\n",
      "dataset-1_byebye_not-confident_001: stream end\n",
      "dataset-1_byebye_old_001: stream end\n",
      "dataset-1_byebye_proud_001: stream end\n",
      "dataset-1_byebye_sad_001: stream end\n",
      "dataset-1_byebye_tired_001: stream end\n",
      "dataset-1_bye_active_001: stream end\n",
      "dataset-1_bye_angry_001: stream end\n",
      "dataset-1_bye_childish_001: stream end\n",
      "dataset-1_bye_chimpira_001: stream end\n",
      "dataset-1_bye_feminine_001: stream end\n",
      "dataset-1_bye_giant_001: stream end\n",
      "dataset-1_bye_happy_001: stream end\n",
      "dataset-1_bye_masculinity_001: stream end\n",
      "dataset-1_bye_musical_001: stream end\n",
      "dataset-1_bye_normal_001: stream end\n",
      "dataset-1_bye_not-confident_001: stream end\n",
      "dataset-1_bye_old_001: stream end\n",
      "dataset-1_bye_proud_001: stream end\n",
      "dataset-1_bye_sad_001: stream end\n",
      "dataset-1_bye_tired_001: stream end\n",
      "dataset-1_call_normal_001: stream end\n",
      "dataset-1_call_normal_002: stream end\n",
      "dataset-1_dance-long_normal_001: stream end\n",
      "dataset-1_dance-short_normal_001: stream end\n",
      "dataset-1_dash_active_001: stream end\n",
      "dataset-1_dash_angry_001: stream end\n",
      "dataset-1_dash_childish_001: stream end\n",
      "dataset-1_dash_chimpira_001: stream end\n",
      "dataset-1_dash_feminine_001: stream end\n",
      "dataset-1_dash_giant_001: stream end\n",
      "dataset-1_dash_happy_001: stream end\n",
      "dataset-1_dash_masculinity_001: stream end\n",
      "dataset-1_dash_musical_001: stream end\n",
      "dataset-1_dash_normal_001: stream end\n",
      "dataset-1_dash_not-confident_001: stream end\n",
      "dataset-1_dash_old_001: stream end\n",
      "dataset-1_dash_proud_001: stream end\n",
      "dataset-1_dash_sad_001: stream end\n",
      "dataset-1_dash_tired_001: stream end\n",
      "dataset-1_guide_active_001: stream end\n",
      "dataset-1_guide_angry_001: stream end\n",
      "dataset-1_guide_childish_001: stream end\n",
      "dataset-1_guide_chimpira_001: stream end\n",
      "dataset-1_guide_feminine_001: stream end\n",
      "dataset-1_guide_giant_001: stream end\n",
      "dataset-1_guide_happy_001: stream end\n",
      "dataset-1_guide_masculinity_001: stream end\n",
      "dataset-1_guide_musical_001: stream end\n",
      "dataset-1_guide_normal_001: stream end\n",
      "dataset-1_guide_not-confident_001: stream end\n",
      "dataset-1_guide_old_001: stream end\n",
      "dataset-1_guide_proud_001: stream end\n",
      "dataset-1_guide_sad_001: stream end\n",
      "dataset-1_guide_tired_001: stream end\n",
      "dataset-1_kick_normal_001: stream end\n",
      "dataset-1_punch_normal_001: stream end\n",
      "dataset-1_punch_normal_002: stream end\n",
      "dataset-1_respond_normal_001: stream end\n",
      "dataset-1_run_active_001: stream end\n",
      "dataset-1_run_angry_001: stream end\n",
      "dataset-1_run_childish_001: stream end\n",
      "dataset-1_run_chimpira_001: stream end\n",
      "dataset-1_run_feminine_001: stream end\n",
      "dataset-1_run_giant_001: stream end\n",
      "dataset-1_run_happy_001: stream end\n",
      "dataset-1_run_masculinity_001: stream end\n",
      "dataset-1_run_musical_001: stream end\n",
      "dataset-1_run_normal_001: stream end\n",
      "dataset-1_run_not-confident_001: stream end\n",
      "dataset-1_run_old_001: stream end\n",
      "dataset-1_run_proud_001: stream end\n",
      "dataset-1_run_sad_001: stream end\n",
      "dataset-1_run_tired_001: stream end\n",
      "dataset-1_slash_normal_001: stream end\n",
      "dataset-1_slash_normal_002: stream end\n",
      "dataset-1_walk-back_active_001: stream end\n",
      "dataset-1_walk-back_angry_001: stream end\n",
      "dataset-1_walk-back_childish_001: stream end\n",
      "dataset-1_walk-back_chimpira_001: stream end\n",
      "dataset-1_walk-back_feminine_001: stream end\n",
      "dataset-1_walk-back_giant_001: stream end\n",
      "dataset-1_walk-back_happy_001: stream end\n",
      "dataset-1_walk-back_masculinity_001: stream end\n",
      "dataset-1_walk-back_musical_001: stream end\n",
      "dataset-1_walk-back_normal_001: stream end\n",
      "dataset-1_walk-back_not-confident_001: stream end\n",
      "dataset-1_walk-back_old_001: stream end\n",
      "dataset-1_walk-back_proud_001: stream end\n",
      "dataset-1_walk-back_sad_001: stream end\n",
      "dataset-1_walk-back_tired_001: stream end\n",
      "dataset-1_walk-left_active_001: stream end\n",
      "dataset-1_walk-left_angry_001: stream end\n",
      "dataset-1_walk-left_childish_001: stream end\n",
      "dataset-1_walk-left_chimpira_001: stream end\n",
      "dataset-1_walk-left_feminine_001: stream end\n",
      "dataset-1_walk-left_giant_001: stream end\n",
      "dataset-1_walk-left_happy_001: stream end\n",
      "dataset-1_walk-left_masculinity_001: stream end\n",
      "dataset-1_walk-left_musical_001: stream end\n",
      "dataset-1_walk-left_normal_001: stream end\n",
      "dataset-1_walk-left_not-confident_001: stream end\n",
      "dataset-1_walk-left_old_001: stream end\n",
      "dataset-1_walk-left_proud_001: stream end\n",
      "dataset-1_walk-left_sad_001: stream end\n",
      "dataset-1_walk-left_tired_001: stream end\n",
      "dataset-1_walk-right_active_001: stream end\n",
      "dataset-1_walk-right_angry_001: stream end\n",
      "dataset-1_walk-right_childish_001: stream end\n",
      "dataset-1_walk-right_chimpira_001: stream end\n",
      "dataset-1_walk-right_feminine_001: stream end\n",
      "dataset-1_walk-right_giant_001: stream end\n",
      "dataset-1_walk-right_happy_001: stream end\n",
      "dataset-1_walk-right_masculinity_001: stream end\n",
      "dataset-1_walk-right_musical_001: stream end\n",
      "dataset-1_walk-right_normal_001: stream end\n",
      "dataset-1_walk-right_not-confident_001: stream end\n",
      "dataset-1_walk-right_old_001: stream end\n",
      "dataset-1_walk-right_proud_001: stream end\n",
      "dataset-1_walk-right_sad_001: stream end\n",
      "dataset-1_walk-right_tired_001: stream end\n",
      "dataset-1_walk_active_001: stream end\n",
      "dataset-1_walk_active_002: stream end\n",
      "dataset-1_walk_angry_001: stream end\n",
      "dataset-1_walk_angry_002: stream end\n",
      "dataset-1_walk_childish_001: stream end\n",
      "dataset-1_walk_childish_002: stream end\n",
      "dataset-1_walk_chimpira_001: stream end\n",
      "dataset-1_walk_chimpira_002: stream end\n",
      "dataset-1_walk_feminine_001: stream end\n",
      "dataset-1_walk_feminine_002: stream end\n",
      "dataset-1_walk_giant_001: stream end\n",
      "dataset-1_walk_giant_002: stream end\n",
      "dataset-1_walk_happy_001: stream end\n",
      "dataset-1_walk_happy_002: stream end\n",
      "dataset-1_walk_masculinity_001: stream end\n",
      "dataset-1_walk_masculinity_002: stream end\n",
      "dataset-1_walk_musical_001: stream end\n",
      "dataset-1_walk_musical_002: stream end\n",
      "dataset-1_walk_normal_001: stream end\n",
      "dataset-1_walk_normal_002: stream end\n",
      "dataset-1_walk_not-confident_001: stream end\n",
      "dataset-1_walk_not-confident_002: stream end\n",
      "dataset-1_walk_old_001: stream end\n",
      "dataset-1_walk_old_002: stream end\n",
      "dataset-1_walk_proud_001: stream end\n",
      "dataset-1_walk_proud_002: stream end\n",
      "dataset-1_walk_sad_001: stream end\n",
      "dataset-1_walk_sad_002: stream end\n",
      "dataset-1_walk_tired_001: stream end\n",
      "dataset-1_walk_tired_002: stream end\n"
     ]
    }
   ],
   "source": [
    "data.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import multiprocessing as mp\n",
    "\n",
    "def load_data(data_path, batch_sz = 5, train_val_test_split = [0.7,0.1,0.2]):\n",
    "    assert sum(train_val_test_split) == 1, \"Train, val and test fractions should sum to 1!\" \n",
    "    dataset = bd.BandaiDataset(data_path)\n",
    "\n",
    "    tr_va_te = []\n",
    "    n_cpus = mp.cpu_count()\n",
    "    for frac in train_val_test_split:\n",
    "        num = round(frac * len(dataset))\n",
    "        tr_va_te.append(num)\n",
    "\n",
    "    train_split, val_split, test_split = random_split(dataset, tr_va_te)\n",
    "    '''\n",
    "    train_dl = DataLoader(train_split,\n",
    "                          batch_size=batch_sz,\n",
    "                          shuffle=True,\n",
    "                          num_workers=n_cpus\n",
    "                        )\n",
    "    val_dl = DataLoader(val_split,\n",
    "                        batch_size=batch_sz,\n",
    "                        shuffle=True,\n",
    "                        num_workers=n_cpus)\n",
    "    test_dl = DataLoader(test_split,\n",
    "                         batch_size=batch_sz,\n",
    "                         shuffle=True,\n",
    "                         num_workers=n_cpus)\n",
    "    '''\n",
    "    #return train_dl, val_dl, test_dl\n",
    "    return train_split, val_split, test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./saved_models\"\n",
    "DATASET_DIR = \"./datasets/data/\"\n",
    "FILELIST_PATH = \"datafiles.txt\"\n",
    "\n",
    "train_dl, val_dl, test_dl = load_data(FILELIST_PATH,DATASET_DIR,batch_sz=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def custom_collate_fn(batch,max_frame):\n",
    "    motion_batch_tensor = torch.FloatTensor(len(batch),max_frame,640,480)\n",
    "    motion_tensors = []\n",
    "    labels = []\n",
    "    for item in batch:\n",
    "        motion = bd.Motion()\n",
    "        motion_tensor = motion.cap_frames(f\"{DATASET_DIR}{item}\")\n",
    "        motion_tensors.append(motion_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-envrionment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
